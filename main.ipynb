{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# Real Estate Web Scraping Project\n\nThis notebook demonstrates a web scraping project focused on extracting real estate data from Redfin. The goal is to collect property information, such as price, number of beds, baths, area and more.\n\n## Libraries Used\n- `requests`: For sending HTTP requests to websites.\n- `BeautifulSoup`: For parsing HTML and extracting data.\n- `pandas`: For organizing and exporting data into a CSV file.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport requests\nresponse = requests.get(\"https://raw.githubusercontent.com/ziadsalama95/real-estate-web-scraping/main/functions.py\")\nwith open(\"functions.py\", \"wb\") as file:\n    file.write(response.content)\nfrom functions import *\nimport pandas as pd\nfrom bs4 import BeautifulSoup","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-08-14T16:30:24.256215Z","iopub.execute_input":"2024-08-14T16:30:24.256591Z","iopub.status.idle":"2024-08-14T16:30:24.949641Z","shell.execute_reply.started":"2024-08-14T16:30:24.256558Z","shell.execute_reply":"2024-08-14T16:30:24.948640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define the URL and headers for scraping","metadata":{}},{"cell_type":"code","source":"BASE_URL = 'https://www.redfin.com/city/30749/NY/New-York'\nHEADERS = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',\n}","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-08-14T16:30:24.951163Z","iopub.execute_input":"2024-08-14T16:30:24.951608Z","iopub.status.idle":"2024-08-14T16:30:24.955964Z","shell.execute_reply.started":"2024-08-14T16:30:24.951580Z","shell.execute_reply":"2024-08-14T16:30:24.954955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_RESULTS = 15000  # Maximum number of homes to scrape","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-08-14T16:30:24.957162Z","iopub.execute_input":"2024-08-14T16:30:24.957454Z","iopub.status.idle":"2024-08-14T16:30:24.966801Z","shell.execute_reply.started":"2024-08-14T16:30:24.957423Z","shell.execute_reply":"2024-08-14T16:30:24.965864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start scraping until the maximum number of results is reached","metadata":{}},{"cell_type":"code","source":"property_list = []","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:30:24.969192Z","iopub.execute_input":"2024-08-14T16:30:24.969852Z","iopub.status.idle":"2024-08-14T16:30:24.977668Z","shell.execute_reply.started":"2024-08-14T16:30:24.969814Z","shell.execute_reply":"2024-08-14T16:30:24.976709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"page_number = 1\nwhile len(property_list) < MAX_RESULTS:\n    try:\n        response = requests.get(f'{BASE_URL}/page-{page_number}', headers=HEADERS)\n        response.raise_for_status()  # Check for request errors\n    except requests.exceptions.RequestException as e:\n        continue\n\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    containers = soup.find_all('div', {'class': 'HomeCardContainer flex justify-center'})\n\n    if not containers:\n        print(\"No more homes found\")\n        break\n\n    for container in containers:\n        address = get_home_address(container)\n        street, neighborhood, zip_code = parse_address(address)\n        property_list.append({\n            'price': get_home_price(container),\n            'beds': get_beds_num(container),\n            'baths': get_baths_num(container),\n            'area_value': get_area_value(container),\n            'area_label': get_area_label(container),\n            'street': street,\n            'neighborhood': neighborhood,\n            'zip_code': zip_code,\n            'listing_by': get_listing_by(container)\n        })\n\n        if len(property_list) >= MAX_RESULTS:\n            break\n\n    print(f\"Got {len(property_list)}, page: {page_number}\")\n    page_number += 1","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-08-14T16:30:24.978839Z","iopub.execute_input":"2024-08-14T16:30:24.979189Z","iopub.status.idle":"2024-08-14T16:37:32.408390Z","shell.execute_reply.started":"2024-08-14T16:30:24.979161Z","shell.execute_reply":"2024-08-14T16:37:32.407353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(property_list)\ndf.drop_duplicates(inplace=True)\ndf.reset_index(inplace=True)\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:37:32.409841Z","iopub.execute_input":"2024-08-14T16:37:32.410139Z","iopub.status.idle":"2024-08-14T16:37:32.440955Z","shell.execute_reply.started":"2024-08-14T16:37:32.410113Z","shell.execute_reply":"2024-08-14T16:37:32.439918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the Data","metadata":{}},{"cell_type":"code","source":"os.makedirs('data', exist_ok=True)\ndf.to_csv('data/homes.csv', index=False)\ndf.sample(5)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-08-14T16:37:32.442376Z","iopub.execute_input":"2024-08-14T16:37:32.442822Z","iopub.status.idle":"2024-08-14T16:37:32.478904Z","shell.execute_reply.started":"2024-08-14T16:37:32.442780Z","shell.execute_reply":"2024-08-14T16:37:32.477752Z"},"trusted":true},"execution_count":null,"outputs":[]}]}